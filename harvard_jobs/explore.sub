#!/bin/bash
#SBATCH --job-name=explore_new     # create a short name for your job
#SBATCH -c 96                # Number of cores (-c)
#SBATCH -t 72:00:00          # Runtime in D-HH:MM, minimum of 10 minutes
#SBATCH --mem=960000           # Memory pool for all cores (see also --mem-per-cpu)
#SBATCH --mail-type=begin        # send email when job begins
#SBATCH --mail-type=end          # send email when job ends
#SBATCH --mail-type=fail         # send email if job fails
#SBATCH --mail-user=zg292@cornell.edu
#SBATCH --gres=gpu:nvidia_h100_80gb_hbm3:4
#SBATCH -o ./runs/output_%j.out  # File to which STDOUT will be written, %j inserts jobid
#SBATCH -e ./runs/errors_%j.err  # File to which STDERR will be written, %j inserts jobid
#SBATCH -p kempner_h100
#SBATCH --account=kempner_kdbrantley_lab

######################
### Set enviroment 
######################

module purge
module load cuda/12.2.0-fasrc01
module load gcc/10.2.0-fasrc01
source /n/sw/Mambaforge-23.11.0-0/etc/profile.d/conda.sh
conda activate zero
export HF_HOME='/n/holylabs/LABS/kdbrantley_lab/Lab/zhaolin'

GPUS_PER_NODE=4
MINI_BATCH_SIZE=128 # number of prompts for each update; each batch we do BATCH_SIZE / MINI_BATCH_SIZE updates
MICRO_BATCH_SIZEPER_DEVICE=2 # reduce to reduce memory but slower
MODEL_SIZE="1.5"

MAX_PROMPT_LENGTH=256
MAX_RESPONSE_LENGTH=1024
DATASET="gsm8k"

entropy_coeffs=(0)
batch_sizes=(256)
lrs=(1e-6)
kl_coef=(0)

######################
### Set Slurm Job
######################
export VLLM_ATTENTION_BACKEND=XFORMERS

# replay weight vs alpha_decay_coefs trade off
CONSERVATIVE="False"
EPOCH=25
REPLAY_SIZE=100000
CRITIC_WARMUP=6
betas=(1e-2)
alphas=(10)
alpha_decay_coefs=(1)
loss_types=("with_g")
normalize_logprobs=("True")
replay_weights=(0)

normalize_gs=("False" "True")
cr_lrs=(1e-5 1e-6)
filter_times=(1 2 4)

for loss_type in "${loss_types[@]}"; do
    for normalize_logprob in "${normalize_logprobs[@]}"; do
        for normalize_g in "${normalize_gs[@]}"; do
            for filter_time in "${filter_times[@]}"; do
                for entropy_coeff in "${entropy_coeffs[@]}"; do
                    for kl in "${kl_coef[@]}"; do
                        for beta in "${betas[@]}"; do
                            for alpha in "${alphas[@]}"; do
                                for alpha_decay_coef in "${alpha_decay_coefs[@]}"; do
                                    for lr in "${lrs[@]}"; do
                                        for cr_lr in "${cr_lrs[@]}"; do
                                            for bs in "${batch_sizes[@]}"; do
                                                for rw in "${replay_weights[@]}"; do
                                                    python3 -m verl.trainer.main_explore \
                                                                algorithm.loss_type=${loss_type} \
                                                                algorithm.normalize_logprob=${normalize_logprob} \
                                                                algorithm.normalize_g=${normalize_g} \
                                                                algorithm.conservative=${CONSERVATIVE} \
                                                                algorithm.beta=${beta} \
                                                                algorithm.alpha=${alpha} \
                                                                algorithm.alpha_decay_coef=${alpha_decay_coef} \
                                                                algorithm.replay_weight=${rw} \
                                                                algorithm.replay_size=${REPLAY_SIZE} \
                                                                data.train_files=/n/holylabs/LABS/kdbrantley_lab/Lab/zhaolin/reasoning/data/${DATASET}/train.parquet \
                                                                data.val_files=/n/holylabs/LABS/kdbrantley_lab/Lab/zhaolin/reasoning/data/${DATASET}/test.parquet \
                                                                data.max_prompt_length=$MAX_PROMPT_LENGTH \
                                                                data.max_response_length=$MAX_RESPONSE_LENGTH \
                                                                data.train_batch_size=${bs} \
                                                                data.val_batch_size=500 \
                                                                data.filter_time=${filter_time} \
                                                                actor_rollout_ref.model.path=Qwen/Qwen2.5-${MODEL_SIZE}B \
                                                                actor_rollout_ref.actor.optim.lr=$lr \
                                                                actor_rollout_ref.actor.ppo_mini_batch_size=$MINI_BATCH_SIZE \
                                                                actor_rollout_ref.actor.ppo_micro_batch_size=$(expr $GPUS_PER_NODE \* $MICRO_BATCH_SIZEPER_DEVICE) \
                                                                actor_rollout_ref.actor.entropy_coeff=${entropy_coeff} \
                                                                actor_rollout_ref.rollout.log_prob_micro_batch_size=$(expr $GPUS_PER_NODE \* $MICRO_BATCH_SIZEPER_DEVICE) \
                                                                actor_rollout_ref.rollout.tensor_model_parallel_size=$GPUS_PER_NODE \
                                                                actor_rollout_ref.rollout.gpu_memory_utilization=0.4 \
                                                                actor_rollout_ref.ref.log_prob_micro_batch_size=$(expr $GPUS_PER_NODE \* $MICRO_BATCH_SIZEPER_DEVICE) \
                                                                critic.optim.lr=${cr_lr} \
                                                                critic.model.path=Qwen/Qwen2.5-${MODEL_SIZE}B \
                                                                critic.ppo_micro_batch_size=$(expr $GPUS_PER_NODE \* $MICRO_BATCH_SIZEPER_DEVICE) \
                                                                algorithm.kl_ctrl.kl_coef=${kl} \
                                                                trainer.logger=['wandb'] \
                                                                +trainer.val_before_train=False \
                                                                trainer.default_hdfs_dir=null \
                                                                trainer.critic_warmup=${CRITIC_WARMUP} \
                                                                trainer.n_gpus_per_node=$GPUS_PER_NODE \
                                                                trainer.nnodes=1 \
                                                                trainer.save_freq=-1 \
                                                                trainer.test_freq=50 \
                                                                trainer.project_name=${DATASET} \
                                                                trainer.experiment_name=qwen2.5-${MODEL_SIZE}b-${loss_type}-${normalize_logprob}-${normalize_g}-${CONSERVATIVE}-cw-${CRITIC_WARMUP}-bs-${bs}-ec-${entropy_coeff}-lr-${lr}-${cr_lr}-kl-${kl}-beta-${beta}-alpha-${alpha}-ad-${alpha_decay_coef}-rw-${rw}-ft-${filter_time} \
                                                                trainer.total_epochs=${EPOCH} # 2>&1 | tee verl_demo.log
                                                done
                                            done
                                        done
                                    done
                                done
                            done
                        done
                    done
                done
            done
        done
    done
done

python3 -m verl.trainer.main_explore \
        algorithm.loss_type=with_g \
        algorithm.normalize_logprob=True \
        algorithm.normalize_g=False \
        algorithm.conservative=False \
        algorithm.beta=1e-4 \
        algorithm.alpha=1 \
        algorithm.replay_weight=0 \
        algorithm.replay_size=1024 \
        data.train_files=/n/holylabs/LABS/kdbrantley_lab/Lab/zhaolin/reasoning/data/gsm8k/train.parquet \
        data.val_files=/n/holylabs/LABS/kdbrantley_lab/Lab/zhaolin/reasoning/data/gsm8k/test.parquet \
        data.max_prompt_length=256 \
        data.max_response_length=1024 \
        data.train_batch_size=512 \
        data.val_batch_size=500 \
        data.filter_time=2 \
        actor_rollout_ref.model.path=Qwen/Qwen2.5-1.5B \
        actor_rollout_ref.actor.optim.lr=1e-6 \
        actor_rollout_ref.actor.ppo_mini_batch_size=128 \
        actor_rollout_ref.actor.ppo_micro_batch_size=8 \
        actor_rollout_ref.actor.entropy_coeff=0 \
        actor_rollout_ref.rollout.log_prob_micro_batch_size=8 \
        actor_rollout_ref.rollout.tensor_model_parallel_size=4 \
        actor_rollout_ref.rollout.gpu_memory_utilization=0.4 \
        actor_rollout_ref.ref.log_prob_micro_batch_size=8 \
        critic.optim.lr=1e-5 \
        critic.model.path=Qwen/Qwen2.5-1.5B \
        critic.ppo_micro_batch_size=8 \
        algorithm.kl_ctrl.kl_coef=0 \
        trainer.logger=['wandb'] \
        +trainer.val_before_train=False \
        trainer.default_hdfs_dir=null \
        trainer.n_gpus_per_node=4 \
        trainer.nnodes=1 \
        trainer.save_freq=-1 \
        trainer.test_freq=50 \
        trainer.project_name=gsm8k \
        trainer.experiment_name=temp \
        trainer.total_epochs=1 2>&1 | tee verl_demo.log